{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bayesian Data Analysis Project: Gene Cluster Analysis Using Single cell RNA-sequencing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction\n",
    "\n",
    "Single-cell RNA sequencing measures RNA-expression levels for individual cells allowing identification of RNA-expression in cell subpopulations. The goal of this study is to cluster the single cell expression profiles into clusters using probilistic modelling and see if these resemblance clusters produced by a skilled bioinformatician.\n",
    "\n",
    "The clustering produced by the bioinformatician is seen below. Some clustering can be seen, however the data also appears relatively noisy\n",
    "\n",
    "<img src=\"figures/bioinf_clusters.png\",width=800>\n",
    "### Dataset\n",
    "\n",
    "The data is obtained from single-cell RNA sequencing of bone marrow from mice. The reads were mapped to the mice genome and each read mapping to a gene were measured as a *count* for the corresponding gene. Data were measured for for 1500 samples and â‰ˆ27000 genes. We selected a subset of 48 interesting genes for furhter study based on a previous  litterature study. Secondly we were also provided with cell-type labels calculated using the method presented in [Franziska et. al. 2015].\n",
    "\n",
    "\n",
    "\n",
    "#### Dataset analysis\n",
    "Due to low amounts of RNA in a single living cell, the dataset is very sparse with 95% of the genes (in the filtered dataset) having a count of zero and approximately 5.5 counts per sample on average.\n",
    "\n",
    "<img src=\"figures/histogram.png\",width=400>\n",
    "\n",
    "Using the TSNE dimensionality reduction algorithm we visualized the complete dataset (27000 genes) and the filtered dataset (48 genes) as seen below. The non-filtered dataset have almost no structure whereas some structure is seen for the filtered dataset. Secondly we also see that the computed cell-type labels show no agreement with the structure in the filtered dataset suggesting that these should not be trusted.\n",
    "<img src=\"figures/tsne_all.png\",width=400>\n",
    "<img src=\"figures/tsne_filtered.png\",width=400>\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Methods and Results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The latent Dirichlet allocation model (LDA) by [Blei et al. 2003] can be seen as an unsupervised model for cluster analysis. LDA is a generative model that from a *hidden* representation optimizes its posterior in order to explain the observed data points. The observed data is perceived as continues count data where each feature is expected to be exchangeable. The model is referred to as a topic model, since it segments the input data points into a latent topic distribution, which is a multinomial representation of the probability of an input data point being in each of *K* topics. The segmentation into topics, can be perceived as clusters in a $k$-dimensional output space (e.g. euclidian) and be analyzed with various similarity/distance measurements.\n",
    "\n",
    "To explain each variable of the LDA model we use the terminology of topic modeling for documents. In the model we have (i) $\\alpha$ Dirichlet prior over the topic distribution of each document, (ii) $\\beta$ Dirichlet prior over the word distribution for each topic, (iii) $\\theta_i$ the multinomial topic distribution for a document $i$ with length $N$, (iv) $\\rho_k$ the word distribution for a topic $k$, (v) $z^k_{ij}$ the topic $k$ for the $i^{th}$ document and the $j^{th}$ word, (vi) $w_{ij}$ is the $j^{th}$ word in document $i$. The plate notation for the model is:\n",
    "\n",
    "<img src=\"figures/lda.png\",width=600>\n",
    "\n",
    "From [Blei et al. 2003] we find that the joint probility for $\\theta_i$ and $z^k_{ij}$ and $w_{ij}$ is given by:\n",
    "$$\n",
    "p(\\theta, z, w|\\alpha, \\beta) = p(\\theta|\\alpha) \\Pi_{n=1}^{N} p(z_n|\\theta)p(w_n|z_n,\\beta) \\ .\n",
    "$$\n",
    "\n",
    "The corresponding probability of a word $w_{ij}$ is given by (please note the infeasible integral over $\\theta$):\n",
    "\n",
    "$$\n",
    "p(w|\\alpha, \\beta) = \\Pi_{d=1}^M \\int p(\\theta_d|\\alpha) \\bigg (\\Pi^{N_d}_{n=1} \\sum_{z_{dn}}p(z_{dn}|\\theta_d)p(w_{dn}|z_{dn},\\beta) \\bigg ) d\\theta_d \\ .\n",
    "$$\n",
    "\n",
    "The probability of the whole corpus is the given by the product over all documents of the above.\n",
    "\n",
    "In this implementation of the LDA model we tread $K$ as a fixed hyper parameter. For the $\\alpha$ and $\\beta$ priors we test symmetric and asymmetric settings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.manifold import TSNE\n",
    "import gzip\n",
    "import cPickle as cpkl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#loading the preprocessed data. See data_processing.ipynb for details\n",
    "with open('preprocessed_data.cpkl','r') as f:\n",
    "    data = cpkl.load(f)\n",
    "    \n",
    "x_train = data['x_train']     #one hot matrix (samples x genes)\n",
    "t_train = data['t_train']     #labels from bioinformatician \n",
    "genes_id = data['genes_id']   \n",
    "genes = data['genes']\n",
    "sampleid = data['sampleid']   #sampleid and words contain the same information as x_train just encoded as sampleid: cell, words: id for seen words  \n",
    "words = data['words']\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## References\n",
    "\n",
    "Paul, Franziska, et al. \"Transcriptional heterogeneity and lineage commitment in myeloid progenitors.\" Cell 163.7 (2015): 1663-1677 \n",
    "\n",
    "Blei, David, et al. \"Latent Dirichlet allocation.\" Journal of Machine Learning Research (2003): 993-1022"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}

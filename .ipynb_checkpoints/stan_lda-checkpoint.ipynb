{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import gzip\n",
    "import matplotlib\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.manifold import TSNE\n",
    "import pystan\n",
    "import lda\n",
    "import lda.datasets\n",
    "import matplotlib.cm as cm\n",
    "import cPickle as cpkl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#loading the preprocessed data. See data_processing.ipynb for details\n",
    "with open('preprocessed_data.cpkl','r') as f:\n",
    "    data = cpkl.load(f)\n",
    "    \n",
    "x_train = data['x_train']     #one hot matrix (samples x genes)\n",
    "t_train = data['t_train']     #labels from bioinformatician \n",
    "genes_id = data['genes_id']   \n",
    "genes = data['genes']\n",
    "sampleid = data['sampleid']   #sampleid and words contain the same information as x_train just encoded as sampleid: cell, words: id for seen words  \n",
    "words = data['words']\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "anon_model_177a53e2209357cea25bf3efc5f97bd6_namespace::anon_model_177a53e2209357cea25bf3efc5f97bd6: w[k0__] is 79, but must be less than or equal to 48",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-6-0199f913f675>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     47\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     48\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 49\u001b[0;31m \u001b[0mfit\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpystan\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstan\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_code\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstan_LDA\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/Users/casperkaae/anaconda2/lib/python2.7/site-packages/pystan/api.pyc\u001b[0m in \u001b[0;36mstan\u001b[0;34m(file, model_name, model_code, fit, data, pars, chains, iter, warmup, thin, init, seed, algorithm, control, sample_file, diagnostic_file, verbose, boost_lib, eigen_lib, n_jobs, **kwargs)\u001b[0m\n\u001b[1;32m    378\u001b[0m                      \u001b[0msample_file\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msample_file\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdiagnostic_file\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdiagnostic_file\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    379\u001b[0m                      \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mverbose\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0malgorithm\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0malgorithm\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcontrol\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcontrol\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 380\u001b[0;31m                      n_jobs=n_jobs, **kwargs)\n\u001b[0m\u001b[1;32m    381\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mfit\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/casperkaae/anaconda2/lib/python2.7/site-packages/pystan/model.pyc\u001b[0m in \u001b[0;36msampling\u001b[0;34m(self, data, pars, chains, iter, warmup, thin, seed, init, sample_file, diagnostic_file, verbose, algorithm, control, n_jobs, **kwargs)\u001b[0m\n\u001b[1;32m    665\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Algorithm must be one of {}\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0malgorithms\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    666\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 667\u001b[0;31m         \u001b[0mfit\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit_class\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    668\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    669\u001b[0m         \u001b[0mm_pars\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfit\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_param_names\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mstanfit4anon_model_177a53e2209357cea25bf3efc5f97bd6_4218874368394502174.pyx\u001b[0m in \u001b[0;36mstanfit4anon_model_177a53e2209357cea25bf3efc5f97bd6_4218874368394502174.StanFit4Model.__cinit__ (/var/folders/cn/zpktrv0n1lvdj0tz9rtjpzs40000gn/T/tmpDrYxFN/stanfit4anon_model_177a53e2209357cea25bf3efc5f97bd6_4218874368394502174.cpp:8410)\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: anon_model_177a53e2209357cea25bf3efc5f97bd6_namespace::anon_model_177a53e2209357cea25bf3efc5f97bd6: w[k0__] is 79, but must be less than or equal to 48"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "# ==============================================================================\n",
    "stan_LDA = \"\"\"\n",
    "\n",
    "data {\n",
    "  int<lower=2> K;               // num topics\n",
    "  int<lower=2> V;               // num words\n",
    "  int<lower=1> M;               // num docs\n",
    "  int<lower=1> N;               // total word instances\n",
    "  int<lower=1,upper=V> w[N];    // word n\n",
    "  int<lower=1,upper=M> doc[N];  // doc ID for word n\n",
    "  vector<lower=0>[K] alpha;     // topic prior\n",
    "  vector<lower=0>[V] beta;      // word prior\n",
    "}\n",
    "parameters {\n",
    "  simplex[K] theta[M];   // topic dist for doc m\n",
    "  simplex[V] phi[K];     // word dist for topic k\n",
    "}\n",
    "model {\n",
    "  for (m in 1:M)  \n",
    "    theta[m] ~ dirichlet(alpha);  // prior\n",
    "  for (k in 1:K)  \n",
    "    phi[k] ~ dirichlet(beta);     // prior\n",
    "  for (n in 1:N) {\n",
    "    real gamma[K];\n",
    "    for (k in 1:K) \n",
    "      gamma[k] <- log(theta[doc[n],k]) + log(phi[k,w[n]]);\n",
    "    increment_log_prob(log_sum_exp(gamma));  // likelihood\n",
    "  }\n",
    "}\n",
    "\"\"\"\n",
    "\n",
    "M,V  = x_train.shape\n",
    "K=5\n",
    "V=48\n",
    "M=1430\n",
    "data = dict(K=K,\n",
    "        V=V,\n",
    "        M=M,\n",
    "        N=np.sum(x_train),\n",
    "        w=words,\n",
    "        doc=sampleid,\n",
    "        alpha=np.ones(K,)*(1./K),\n",
    "        beta=np.ones(V,)*(1./V),\n",
    "           )\n",
    "\n",
    "\n",
    "fit = pystan.stan(model_code=stan_LDA, data=data)\n",
    "\n",
    "\n",
    "samples = fit.extract"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1430, 48)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "M,V"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
